{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "import unicodedata\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.utils import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.layers import LSTM, Dropout, Dense\n",
    "from keras.models import Sequential\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.losses import mean_squared_error\n",
    "from keras_tuner.tuners import RandomSearch\n",
    "from keras_tuner.engine.hyperparameters import HyperParameters\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def datapipeline(pathfile):\n",
    "    df=pd.read_csv(pathfile)\n",
    "    df.drop_duplicates(subset=\"headline\",\n",
    "                     keep='last', inplace=True)\n",
    "    print(df.head())\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                             headline  is_sarcastic\n",
      "8   report: there still time to convert to christi...             1\n",
      "9                       education reform and evidence             0\n",
      "15                         the new new net neutrality             0\n",
      "27  confused zoo officials awkwardly celebrate aft...             1\n",
      "28  lauren graham just dropped a clue about those ...             0\n"
     ]
    }
   ],
   "source": [
    "filepath='/Users/rianrachmanto/pypro/project/sarcastic_detection/data/Train_Data.csv'\n",
    "df=datapipeline(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextPreprocessor:\n",
    "    def __init__(self):\n",
    "        self.stop = set(stopwords.words('english'))\n",
    "        punctuation = list(string.punctuation)\n",
    "        self.stop.update(punctuation)\n",
    "\n",
    "    def strip_html(self, text):\n",
    "        soup = BeautifulSoup(text, \"html.parser\")\n",
    "        return soup.get_text()\n",
    "\n",
    "    def remove_between_square_brackets(self, text):\n",
    "        return re.sub(r'\\[[^]]*\\]', '', text)\n",
    "\n",
    "    def remove_urls(self, text):\n",
    "        return re.sub(r'http\\S+', '', text)\n",
    "\n",
    "    def remove_stopwords(self, text):\n",
    "        final_text = []\n",
    "        for word in text.split():\n",
    "            if word.strip().lower() not in self.stop:\n",
    "                final_text.append(word.strip())\n",
    "        return \" \".join(final_text)\n",
    "\n",
    "    def remove_accented_chars(self, text):\n",
    "        return unicodedata.normalize('NFKD', text).encode('ascii', 'ignore').decode('utf-8', 'ignore')\n",
    "\n",
    "    def remove_punctuation(self, text):\n",
    "        return re.sub(r'[^a-zA-Z0-9]', ' ', text)\n",
    "\n",
    "    def remove_irrelevant_chars(self, text):\n",
    "        return re.sub(r'[^a-zA-Z]', ' ', text)\n",
    "\n",
    "    def remove_extra_whitespaces(self, text):\n",
    "        return re.sub(r'^\\s*|\\s\\s*', ' ', text).strip()\n",
    "    \n",
    "    def lemmatize_words(self,text):\n",
    "        lemmatizer = WordNetLemmatizer()\n",
    "        words = text.split()\n",
    "        words = [lemmatizer.lemmatize(word,pos='v') for word in words]\n",
    "        return ' '.join(words)\n",
    "\n",
    "    def preprocess_text(self, text):\n",
    "        text = self.strip_html(text)\n",
    "        text = self.remove_between_square_brackets(text)\n",
    "        text = self.remove_urls(text)\n",
    "        text = self.remove_stopwords(text)\n",
    "        text = self.remove_accented_chars(text)\n",
    "        text = self.remove_punctuation(text)\n",
    "        text = self.remove_irrelevant_chars(text)\n",
    "        text = self.remove_extra_whitespaces(text)\n",
    "        return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-36-78ee50dbd512>:8: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
      "  soup = BeautifulSoup(text, \"html.parser\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                             headline  is_sarcastic\n",
      "8   report still time convert christianity christm...             1\n",
      "9                           education reform evidence             0\n",
      "15                             new new net neutrality             0\n",
      "27  confused zoo officials awkwardly celebrate end...             1\n",
      "28  lauren graham dropped clue final gilmore girls...             0\n"
     ]
    }
   ],
   "source": [
    "preprocessor=TextPreprocessor()\n",
    "df['headline']=df['headline'].apply(lambda x:preprocessor.preprocess_text(x))\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create function to tokenize, pad, split data to X_train, X_test, y_train, y_test\n",
    "def tokenize_pad_split(df):\n",
    "    tokenizer = Tokenizer()\n",
    "    tokenizer.fit_on_texts(df['headline'])\n",
    "    X = tokenizer.texts_to_sequences(df['headline'])\n",
    "    X = pad_sequences(X, maxlen=100)\n",
    "    y = df['is_sarcastic']\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test=tokenize_pad_split(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import LSTM, Dropout, Dense\n",
    "from keras.models import Sequential\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.losses import mean_squared_error\n",
    "from keras_tuner.tuners import RandomSearch\n",
    "from keras_tuner.engine.hyperparameters import HyperParameters\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class CustomModelTrainer:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    @staticmethod\n",
    "    def build_model(hp):\n",
    "        with tf.device('/cpu:0'):\n",
    "            model = Sequential()\n",
    "            model.add(LSTM(hp.Int('units',min_value=32,max_value=512,step=32), input_shape=((X_train.shape[1], 1))))\n",
    "            model.add(Dense(1))\n",
    "            model.compile(loss='mse', optimizer='adam',metrics = [tf.keras.metrics.MeanSquaredError()])\n",
    "            return model\n",
    "\n",
    "    def tune_hyperparameters(self, X_train, y_train):\n",
    "        tuner = RandomSearch(\n",
    "            self.build_model,\n",
    "            objective='mean_squared_error',\n",
    "            max_trials=10,  # Adjust the number of trials as needed\n",
    "            directory='keras_tuner',  # Directory to store logs and results\n",
    "            project_name='custom_model'\n",
    "        )\n",
    "\n",
    "        # Define a callback to stop training early if necessary\n",
    "        stop_early = keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)\n",
    "\n",
    "        tuner.search(X_train, y_train, epochs=10, batch_size=32, validation_split=0.2, callbacks=[stop_early])\n",
    "\n",
    "        # Get the best hyperparameters\n",
    "        best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "\n",
    "        return best_hps\n",
    "\n",
    "    def train_best_model(self, X_train, y_train, X_test, y_test):\n",
    "        best_hps = self.tune_hyperparameters(X_train, y_train)\n",
    "\n",
    "        # Build the best model with the tuned hyperparameters\n",
    "        best_model = self.build_model(best_hps)\n",
    "\n",
    "        # Train the best model\n",
    "        best_model.fit(X_train, y_train, epochs=10, batch_size=32, validation_split=0.2)\n",
    "\n",
    "        # Evaluate the best model\n",
    "        self.evaluate_model(best_model, X_test, y_test, save_path=\"/Users/rianrachmanto/pypro/project/sarcastic_detection/model\")\n",
    "    \n",
    "    @staticmethod\n",
    "    def evaluate_model(model, X_test, y_test, save_path=None):\n",
    "        y_pred = model.predict(X_test)\n",
    "        y_pred = (y_pred > 0.5)  # Adjust the threshold as needed\n",
    "        print(confusion_matrix(y_test, y_pred))\n",
    "        print(classification_report(y_test, y_pred))\n",
    "\n",
    "        if save_path:\n",
    "            os.makedirs(save_path, exist_ok=True)\n",
    "            model.save(os.path.join(save_path, 'trained_model.h5'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = CustomModelTrainer()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 10 Complete [00h 02m 14s]\n",
      "mean_squared_error: 0.22470971941947937\n",
      "\n",
      "Best mean_squared_error So Far: 0.22470971941947937\n",
      "Total elapsed time: 00h 34m 59s\n",
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    }
   ],
   "source": [
    "best_hps = trainer.tune_hyperparameters(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reloading Tuner from keras_tuner/custom_model/tuner0.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reloading Tuner from keras_tuner/custom_model/tuner0.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "542/542 [==============================] - 16s 27ms/step - loss: 0.2403 - mean_squared_error: 0.2403 - val_loss: 0.2388 - val_mean_squared_error: 0.2388\n",
      "Epoch 2/10\n",
      "542/542 [==============================] - 14s 25ms/step - loss: 0.2373 - mean_squared_error: 0.2373 - val_loss: 0.2382 - val_mean_squared_error: 0.2382\n",
      "Epoch 3/10\n",
      "542/542 [==============================] - 13s 25ms/step - loss: 0.2356 - mean_squared_error: 0.2356 - val_loss: 0.2366 - val_mean_squared_error: 0.2366\n",
      "Epoch 4/10\n",
      "542/542 [==============================] - 13s 25ms/step - loss: 0.2349 - mean_squared_error: 0.2349 - val_loss: 0.2382 - val_mean_squared_error: 0.2382\n",
      "Epoch 5/10\n",
      "542/542 [==============================] - 13s 24ms/step - loss: 0.2347 - mean_squared_error: 0.2347 - val_loss: 0.2365 - val_mean_squared_error: 0.2365\n",
      "Epoch 6/10\n",
      "542/542 [==============================] - 13s 24ms/step - loss: 0.2344 - mean_squared_error: 0.2344 - val_loss: 0.2354 - val_mean_squared_error: 0.2354\n",
      "Epoch 7/10\n",
      "542/542 [==============================] - 13s 25ms/step - loss: 0.2331 - mean_squared_error: 0.2331 - val_loss: 0.2350 - val_mean_squared_error: 0.2350\n",
      "Epoch 8/10\n",
      "542/542 [==============================] - 13s 24ms/step - loss: 0.2355 - mean_squared_error: 0.2355 - val_loss: 0.2369 - val_mean_squared_error: 0.2369\n",
      "Epoch 9/10\n",
      "542/542 [==============================] - 13s 25ms/step - loss: 0.2330 - mean_squared_error: 0.2330 - val_loss: 0.2367 - val_mean_squared_error: 0.2367\n",
      "Epoch 10/10\n",
      "542/542 [==============================] - 13s 24ms/step - loss: 0.2321 - mean_squared_error: 0.2321 - val_loss: 0.2327 - val_mean_squared_error: 0.2327\n",
      "170/170 [==============================] - 2s 9ms/step\n",
      "[[2449  426]\n",
      " [1741  796]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.85      0.69      2875\n",
      "           1       0.65      0.31      0.42      2537\n",
      "\n",
      "    accuracy                           0.60      5412\n",
      "   macro avg       0.62      0.58      0.56      5412\n",
      "weighted avg       0.62      0.60      0.57      5412\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trainer.train_best_model(X_train, y_train, X_test, y_test)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
